{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io.wavfile import read \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the address in 'url' variable\n",
    "data_path = \"dsl_data/development.csv\"\n",
    "# Importing the file from the address contained in 'url' into 'df' \n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check null values in Training dataset (pandas dataframe)\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['none' 'music' 'lights' 'volume' 'heat']\n",
      "['change language' 'activate' 'deactivate' 'increase' 'decrease']\n"
     ]
    }
   ],
   "source": [
    "# To get unique values in order to map values to objects imported from src/data.py\n",
    "\n",
    "print(df['object'].unique())\n",
    "print(df['action'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9854, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dict_data \n",
    "\n",
    "df['gender'] = df['gender'].map(dict_data.gender_map)\n",
    "df['Self-reported fluency level '] = df['Self-reported fluency level '].map(dict_data.language_fluency_map)\n",
    "df['ageRange'] = df['ageRange'].map(dict_data.age_range_map)\n",
    "df['Current language used for work/school'] = df['Current language used for work/school'].map(dict_data.current_language_map)\n",
    "df['First Language spoken'] = df['First Language spoken'].map(dict_data.first_language_map)\n",
    "\n",
    "\n",
    "# Try to combine action & object in 1 column\n",
    "df[\"action-object\"] = df['action'].astype(str) +\"-\"+ df[\"object\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "duration_array = []\n",
    "zcr_mean_array = []\n",
    "zcr_std_array = []\n",
    "mfcc_array = []\n",
    "chroma_cens_array = []\n",
    "\n",
    "\n",
    "for audio in df['path']:\n",
    "    # rate, data = read(audio, mmap=False) \n",
    "\n",
    "    # Load audio files (wav) as amplitude and rate using \n",
    "    # Default rate: 22050\n",
    "    data ,rate = librosa.load(audio)\n",
    "\n",
    "    # Calculate zero crossing rate\n",
    "    zcr = librosa.zero_crossings(data)\n",
    "\n",
    "    # Calculate mean of zero crossing rate\n",
    "    zcr_mean = np.mean(zcr)\n",
    "    zcr_mean_array.append(zcr_mean) \n",
    "\n",
    "    # Calculate standard deviation of zero crossing rate\n",
    "    zcr_std = np.std(zcr)\n",
    "    zcr_std_array.append(zcr_std) \n",
    "\n",
    "    #  extract Mel-Frequency Cepstral Coefficients (MFCCs) from audio signal and compute mean on rows\n",
    "    mfcc = librosa.feature.mfcc(y=data, sr=rate, n_mfcc=50)\n",
    "    mfcc_mean = np.mean(mfcc,axis=1)\n",
    "    mfcc_array.append(mfcc_mean) \n",
    "   \n",
    "    # Extract Chroma cens feature\n",
    "    chroma_cens = librosa.feature.chroma_cens(y=data, sr=rate)\n",
    "    chroma_cens_mean = np.mean(chroma_cens,axis=1)\n",
    "    chroma_cens_array.append(chroma_cens_mean)\n",
    "   \n",
    "    # Get duration by dividing number of columns in data by rate (Number of channels)\n",
    "    duration_array.append(data.shape[0] / rate)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['zcr_mean'] = zcr_mean_array\n",
    "df['zcr_std'] = zcr_std_array\n",
    "df['duration'] = duration_array \n",
    "df['mfcc'] = mfcc_array \n",
    "df['chroma_cens'] = chroma_cens_array \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# extract the array column\n",
    "array_column = df['mfcc']\n",
    "\n",
    "# reshape the array to several columns\n",
    "array_column = array_column.apply(pd.Series)\n",
    "\n",
    "# rename the columns\n",
    "\n",
    "array_column.columns = [f'mfcc_{i}' for i in range(array_column.shape[1])]\n",
    "\n",
    "# join the new DataFrame with the original one\n",
    "df = pd.concat([df, array_column], axis=1)\n",
    "\n",
    "# drop the array column\n",
    "df = df.drop('mfcc', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# extract the array column\n",
    "array_column = df['chroma_cens']\n",
    "\n",
    "# reshape the array to several columns\n",
    "array_column = array_column.apply(pd.Series)\n",
    "\n",
    "# rename the columns\n",
    "\n",
    "array_column.columns = [f'chroma_cens_{i}' for i in range(array_column.shape[1])]\n",
    "\n",
    "# join the new DataFrame with the original one\n",
    "df = pd.concat([df, array_column], axis=1)\n",
    "\n",
    "# drop the array column\n",
    "df = df.drop('chroma_cens', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('file_name.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "static_features_array = ['Self-reported fluency level ','First Language spoken', 'Current language used for work/school', 'gender', 'ageRange','zcr_mean','zcr_std','duration']\n",
    "dynamic_features_array1 = [f'mfcc_{x}' for x in range(50)]\n",
    "dynamic_features_array2 = [f'chroma_cens_{x}' for x in range(12)]\n",
    "\n",
    "\n",
    "dynamic_features_array = np.concatenate((dynamic_features_array1, dynamic_features_array2))\n",
    "\n",
    "all_features_array = np.concatenate((static_features_array, dynamic_features_array))\n",
    "\n",
    "# x = df_copy[all_features_array]\n",
    "x = df[all_features_array].copy()\n",
    "y = df[['action-object']].copy()\n",
    "\n",
    "\n",
    "#train_test_split splits the data into 70% training data and 30% test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus rog\\AppData\\Local\\Temp\\ipykernel_16796\\252704369.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf_clf.fit(x_train,y_train)\n"
     ]
    }
   ],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Classifier\n",
    "rf_clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "rf_clf.fit(x_train,y_train)\n",
    "y_pred_rf=rf_clf.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm_clf = svm.SVC()\n",
    "svm_clf.fit(x_train,y_train)\n",
    "y_pred_svm=svm_clf.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# clf = DecisionTreeClassifier(max_depth = 10, min_impurity_decrease=0.01)\n",
    "# clf.fit(x_train, y_train)\n",
    "# y_pred = clf.predict(x_test)\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy Random Forest: 0.41494758200879267\n",
      "Test set accuracy using SVM: 0.3043625295908015\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy using test data (25%)\n",
    "print(\"Test set accuracy Random Forest:\",metrics.accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Test set accuracy using SVM:\",metrics.accuracy_score(y_test, y_pred_svm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\venv\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=471\n",
      "  return f(*args, **kwargs)\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\venv\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=960\n",
      "  return f(*args, **kwargs)\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\venv\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=864\n",
      "  return f(*args, **kwargs)\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\venv\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=588\n",
      "  return f(*args, **kwargs)\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\venv\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=294\n",
      "  return f(*args, **kwargs)\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\venv\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=928\n",
      "  return f(*args, **kwargs)\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\venv\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=608\n",
      "  return f(*args, **kwargs)\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\venv\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=236\n",
      "  return f(*args, **kwargs)\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\venv\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=480\n",
      "  return f(*args, **kwargs)\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\venv\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: n_fft=1024 is too small for input signal of length=992\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Storing the address in 'url' variable\n",
    "evaluation_path =   \"dsl_data/evaluation.csv\"\n",
    "\n",
    "# Importing the csv file from the address contained in 'url' into 'evaluation_df' \n",
    "evaluation_df = pd.read_csv(evaluation_path)\n",
    "\n",
    "\n",
    "\n",
    "# Check null values in Training dataset (pandas dataframe)\n",
    "evaluation_df.isnull().sum().sum()\n",
    "\n",
    "import dict_data \n",
    "\n",
    "# map features in evaluation_df to predefined dictionaries\n",
    "evaluation_df['gender'] = evaluation_df['gender'].map(dict_data.gender_map)\n",
    "evaluation_df['Self-reported fluency level '] = evaluation_df['Self-reported fluency level '].map(dict_data.language_fluency_map)\n",
    "evaluation_df['ageRange'] = evaluation_df['ageRange'].map(dict_data.age_range_map)\n",
    "evaluation_df['Current language used for work/school'] = evaluation_df['Current language used for work/school'].map(dict_data.current_language_map)\n",
    "evaluation_df['First Language spoken'] = evaluation_df['First Language spoken'].map(dict_data.first_language_map)\n",
    "\n",
    "\n",
    "import librosa\n",
    "\n",
    "chroma_cens_array = []\n",
    "duration_array = []\n",
    "zcr_mean_array = []\n",
    "zcr_std_array = []\n",
    "mfcc_array = []\n",
    "\n",
    "\n",
    "for audio in evaluation_df['path']:\n",
    "    # Load audio files (wav) as amplitude and rate using \n",
    "    # Default rate: 22050\n",
    "    data ,rate = librosa.load(audio)\n",
    "\n",
    "    # Calculate zero crossing rate\n",
    "    zcr = librosa.zero_crossings(data)\n",
    "\n",
    "    # Calculate mean of zero crossing rate\n",
    "    zcr_mean = np.mean(zcr)\n",
    "    zcr_mean_array.append(zcr_mean) \n",
    "\n",
    "    # Calculate standard deviation of zero crossing rate\n",
    "    zcr_std = np.std(zcr)\n",
    "    zcr_std_array.append(zcr_std) \n",
    "\n",
    "\n",
    "    #  Extract Mel-Frequency Cepstral Coefficients (MFCCs) from audio signal and compute mean on rows\n",
    "    mfcc = librosa.feature.mfcc(y=data, sr=rate, n_mfcc=50)\n",
    "    mfcc_mean = np.mean(mfcc,axis=1)\n",
    "    mfcc_array.append(mfcc_mean) \n",
    "\n",
    "    # Extract Chroma cens feature\n",
    "    chroma_cens = librosa.feature.chroma_cens(y=data, sr=rate)\n",
    "    chroma_cens_mean = np.mean(chroma_cens,axis=1)\n",
    "    chroma_cens_array.append(chroma_cens_mean)\n",
    "\n",
    "    # Get duration by dividing number of columns in data by rate (Number of channels)\n",
    "    duration_array.append(data.shape[0] / rate)\n",
    "\n",
    "\n",
    "evaluation_df['zcr_mean'] = zcr_mean_array\n",
    "evaluation_df['zcr_std'] = zcr_std_array\n",
    "evaluation_df['duration'] = duration_array \n",
    "evaluation_df['mfcc'] = mfcc_array \n",
    "evaluation_df['chroma_cens'] = chroma_cens_array \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x_evaluation = evaluation_df[['Self-reported fluency level ','First Language spoken', 'Current language used for work/school', 'gender', 'ageRange', 'zero_crossing','duration','mfcc']].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the array column\n",
    "array_column = evaluation_df['mfcc']\n",
    "\n",
    "# reshape the array to several columns\n",
    "array_column = array_column.apply(pd.Series)\n",
    "\n",
    "# rename the columns\n",
    "\n",
    "array_column.columns = [f'mfcc_{i}' for i in range(array_column.shape[1])]\n",
    "\n",
    "# join the new DataFrame with the original one\n",
    "evaluation_df = pd.concat([evaluation_df, array_column], axis=1)\n",
    "\n",
    "# drop the array column\n",
    "evaluation_df = evaluation_df.drop('mfcc', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# extract the array column\n",
    "array_column = evaluation_df['chroma_cens']\n",
    "\n",
    "# reshape the array to several columns\n",
    "array_column = array_column.apply(pd.Series)\n",
    "\n",
    "# rename the columns\n",
    "\n",
    "array_column.columns = [f'chroma_cens_{i}' for i in range(array_column.shape[1])]\n",
    "\n",
    "# join the new DataFrame with the original one\n",
    "evaluation_df = pd.concat([evaluation_df, array_column], axis=1)\n",
    "\n",
    "# drop the array column\n",
    "evaluation_df = evaluation_df.drop('chroma_cens', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_df.to_csv('file_name2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "static_features_array = ['Self-reported fluency level ','First Language spoken', 'Current language used for work/school', 'gender', 'ageRange','zcr_mean','zcr_std','duration']\n",
    "dynamic_features_array1 = [f'mfcc_{x}' for x in range(50)]\n",
    "dynamic_features_array2 = [f'chroma_cens_{x}' for x in range(12)]\n",
    "\n",
    "\n",
    "dynamic_features_array = np.concatenate((dynamic_features_array1, dynamic_features_array2))\n",
    "\n",
    "\n",
    "all_features_array = np.concatenate((static_features_array, dynamic_features_array))\n",
    "\n",
    "# x = df_copy[all_features_array]\n",
    "x_evaluation = evaluation_df[all_features_array].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_evaluation=rf_clf.predict(x_evaluation)\n",
    "\n",
    "y_evaluation = list(map(lambda s: s.replace(\"-\", \"\"), y_evaluation))\n",
    "\n",
    "y_evaluation_df = pd.DataFrame(y_evaluation, columns = ['Predicted'])\n",
    "y_evaluation_df.index.name = 'Id'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "now = int(time.time())\n",
    "\n",
    "y_evaluation_df.to_csv(f'evaluation/predictions{now}.csv',index=True,header=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a6207722f3be5c8aeec7a028becc5489fbd28a1705747404dde5b96b7146bf2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
