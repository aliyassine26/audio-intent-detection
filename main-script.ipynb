{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io.wavfile import read \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the address in 'url' variable\n",
    "data_path =   \"dsl_data/development.csv\"\n",
    "# Importing the file from the address contained in 'url' into 'df' \n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null values in Training dataset (pandas dataframe)\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get unique values in order to map values to objects imported from src/data.py\n",
    "\n",
    "print(df['object'].unique())\n",
    "print(df['action'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dict_data \n",
    "\n",
    "df['gender'] = df['gender'].map(dict_data.gender_map)\n",
    "df['Self-reported fluency level '] = df['Self-reported fluency level '].map(dict_data.language_fluency_map)\n",
    "df['ageRange'] = df['ageRange'].map(dict_data.age_range_map)\n",
    "df['Current language used for work/school'] = df['Current language used for work/school'].map(dict_data.current_language_map)\n",
    "df['First Language spoken'] = df['First Language spoken'].map(dict_data.first_language_map)\n",
    "\n",
    "\n",
    "# Try to combine action & object in 1 column\n",
    "df[\"action-object\"] = df['action'].astype(str) +\"-\"+ df[\"object\"]\n",
    "\n",
    "# df = df.iloc[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "# audios_array = []\n",
    "# duration_array = []\n",
    "# zero_crossing_array = []\n",
    "mfcc_array = []\n",
    "\n",
    "\n",
    "\n",
    "for audio in df['path']:\n",
    "    # rate, data = read(audio, mmap=False) \n",
    "\n",
    "    # Load audio files (wav) as amplitude and rate using \n",
    "    # Default rate: 22050\n",
    "    data ,rate = librosa.load(audio)\n",
    "\n",
    "    # zero_crossing_array.append(sum(librosa.zero_crossings(data)))\n",
    "    # audios_array.append(data)\n",
    "\n",
    "    # feature_vector = get_feature_vector(data, rate)\n",
    "    # norm_audios_feat.append(feature_vector) \n",
    "\n",
    "    # mfcc = librosa.feature.mfcc(y=data, sr=rate)\n",
    "    mfcc = librosa.feature.mfcc(y=data, sr=rate, n_mfcc=50)\n",
    "    mfcc_mean = np.mean(mfcc,axis=1)\n",
    "    \n",
    "    mfcc_array.append(mfcc_mean) \n",
    "\n",
    "    # X = librosa.stft(data)\n",
    "    # Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    # print(\"Xdb\",Xdb.shape)\n",
    "    # print(\"X\",X.shape)\n",
    "    # Get duration by dividing number of columns in data by rate (Number of channels)\n",
    "    # duration_array.append(data.shape[0] / rate)\n",
    "\n",
    "\n",
    "# df['zero_crossing'] = zero_crossing_array\n",
    "# df['audio'] = audios_array \n",
    "# df['duration'] = duration_array \n",
    "df['mfcc'] = mfcc_array \n",
    "\n",
    "\n",
    "# we can realize two different sample rates for our wav files 16000 & 22050\n",
    "# print(df.rate.value_counts())\n",
    "# print(df.rate.unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# extract the array column\n",
    "array_column = df['mfcc']\n",
    "\n",
    "# reshape the array to several columns\n",
    "array_column = array_column.apply(pd.Series)\n",
    "\n",
    "# rename the columns\n",
    "\n",
    "array_column.columns = [f'mfcc_{i}' for i in range(array_column.shape[1])]\n",
    "\n",
    "# join the new DataFrame with the original one\n",
    "df = pd.concat([df, array_column], axis=1)\n",
    "\n",
    "# drop the array column\n",
    "df = df.drop('mfcc', axis=1)\n",
    "\n",
    "df.to_csv('file_name.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "static_features_array = ['Self-reported fluency level ','First Language spoken', 'Current language used for work/school', 'gender', 'ageRange']\n",
    "dynamic_features_array = [f'mfcc_{x}' for x in range(50)]\n",
    "\n",
    "all_features_array = np.concatenate((static_features_array, dynamic_features_array))\n",
    "\n",
    "# x = df_copy[all_features_array]\n",
    "x = df[all_features_array].copy()\n",
    "y = df[['action-object']].copy()\n",
    "\n",
    "\n",
    "#train_test_split splits the data into 70% training data and 30% test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Classifier\n",
    "rf_clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "rf_clf.fit(x_train,y_train)\n",
    "y_pred_rf=rf_clf.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm_clf = svm.SVC()\n",
    "svm_clf.fit(x_train,y_train)\n",
    "y_pred_svm=svm_clf.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# clf = DecisionTreeClassifier(max_depth = 10, min_impurity_decrease=0.01)\n",
    "# clf.fit(x_train, y_train)\n",
    "# y_pred = clf.predict(x_test)\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy using test data (25%)\n",
    "print(\"Test set accuracy Random Forest:\",metrics.accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Test set accuracy using SVM:\",metrics.accuracy_score(y_test, y_pred_svm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the address in 'url' variable\n",
    "evaluation_path =   \"dsl_data/evaluation.csv\"\n",
    "\n",
    "# Importing the csv file from the address contained in 'url' into 'evaluation_df' \n",
    "evaluation_df = pd.read_csv(evaluation_path)\n",
    "\n",
    "# Check null values in Training dataset (pandas dataframe)\n",
    "evaluation_df.isnull().sum().sum()\n",
    "\n",
    "import dict_data \n",
    "\n",
    "# map features in evaluation_df to predefined dictionaries\n",
    "evaluation_df['gender'] = evaluation_df['gender'].map(dict_data.gender_map)\n",
    "evaluation_df['Self-reported fluency level '] = evaluation_df['Self-reported fluency level '].map(dict_data.language_fluency_map)\n",
    "evaluation_df['ageRange'] = evaluation_df['ageRange'].map(dict_data.age_range_map)\n",
    "evaluation_df['Current language used for work/school'] = evaluation_df['Current language used for work/school'].map(dict_data.current_language_map)\n",
    "evaluation_df['First Language spoken'] = evaluation_df['First Language spoken'].map(dict_data.first_language_map)\n",
    "\n",
    "\n",
    "import librosa\n",
    "\n",
    "audios_array = []\n",
    "duration_array = []\n",
    "zero_crossing_array = []\n",
    "mfcc_array = []\n",
    "\n",
    "\n",
    "\n",
    "for audio in evaluation_df['path']:\n",
    "    # Load audio files (wav) as amplitude and rate using \n",
    "    # Default rate: 22050\n",
    "    data ,rate = librosa.load(audio)\n",
    "\n",
    "    # zero_crossing_array.append(sum(librosa.zero_crossings(data)))\n",
    "    \n",
    "    mfcc = librosa.feature.mfcc(y=data, sr=rate, n_mfcc=50)\n",
    "    mfcc_mean = np.mean(mfcc,axis=1)\n",
    "    \n",
    "    mfcc_array.append(mfcc_mean) \n",
    "    # duration_array.append(data.shape[0] / rate)\n",
    "\n",
    "\n",
    "\n",
    "# evaluation_df['zero_crossing'] = zero_crossing_array\n",
    "# evaluation_df['duration'] = duration_array \n",
    "evaluation_df['mfcc'] = mfcc_array \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x_evaluation = evaluation_df[['Self-reported fluency level ','First Language spoken', 'Current language used for work/school', 'gender', 'ageRange', 'zero_crossing','duration','mfcc']].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the array column\n",
    "array_column = evaluation_df['mfcc']\n",
    "\n",
    "# reshape the array to several columns\n",
    "array_column = array_column.apply(pd.Series)\n",
    "\n",
    "# rename the columns\n",
    "\n",
    "array_column.columns = [f'mfcc_{i}' for i in range(array_column.shape[1])]\n",
    "\n",
    "# join the new DataFrame with the original one\n",
    "evaluation_df = pd.concat([evaluation_df, array_column], axis=1)\n",
    "\n",
    "# drop the array column\n",
    "evaluation_df = evaluation_df.drop('mfcc', axis=1)\n",
    "\n",
    "evaluation_df.to_csv('file_name2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "static_features_array = ['Self-reported fluency level ','First Language spoken', 'Current language used for work/school', 'gender', 'ageRange']\n",
    "dynamic_features_array = [f'mfcc_{x}' for x in range(50)]\n",
    "\n",
    "all_features_array = np.concatenate((static_features_array, dynamic_features_array))\n",
    "\n",
    "# x = df_copy[all_features_array]\n",
    "x_evaluation = evaluation_df[all_features_array].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_evaluation=rf_clf.predict(x_evaluation)\n",
    "for element in y_evaluation:\n",
    "    element = element.replace(\"-\", \"\")\n",
    "    print(element)\n",
    "\n",
    "\n",
    "remove_dash = list(map(lambda s: s.replace(\"-\", \"\"), y_evaluation))\n",
    "print(y_evaluation)\n",
    "\n",
    "# print map(lambda s: s.replace('-' , 'n'), y_evaluation)\n",
    "\n",
    "\n",
    "\n",
    "y_evaluation_df = pd.DataFrame(y_evaluation, columns = ['Predicted'])\n",
    "print(y_evaluation_df)\n",
    "y_evaluation_df.index.name = 'Id'\n",
    "\n",
    "\n",
    "\n",
    "y_evaluation_df.to_csv('predictions2.csv',index=True,header=True)\n",
    "print(y_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Dec 15 2022, 17:11:09) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "967d7ae4cdf3c70afb0a134b5c0d70149760a947b9540b30f419f62add332b4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
