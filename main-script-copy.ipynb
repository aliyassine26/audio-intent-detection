{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io.wavfile import read \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from algorithms import get_features\n",
    "import dict_data \n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the address in 'url' variable\n",
    "data_path = \"dsl_data/development.csv\"\n",
    "evaluation_path = \"dsl_data/evaluation.csv\"\n",
    "\n",
    "# Importing the file from the address contained in 'url' into 'df' \n",
    "df = pd.read_csv(data_path)\n",
    "evaluation_df = pd.read_csv(evaluation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null values in Training dataset (pandas dataframe)\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null values in Evaluation dataset (pandas dataframe)\n",
    "evaluation_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'] = df['gender'].map(dict_data.gender_map)\n",
    "df['Self-reported fluency level '] = df['Self-reported fluency level '].map(dict_data.language_fluency_map)\n",
    "df['ageRange'] = df['ageRange'].map(dict_data.age_range_map)\n",
    "df['Current language used for work/school'] = df['Current language used for work/school'].map(dict_data.current_language_map)\n",
    "df['First Language spoken'] = df['First Language spoken'].map(dict_data.first_language_map)\n",
    "\n",
    "\n",
    "# Try to combine action & object in 1 column\n",
    "df[\"action-object\"] = df['action'].astype(str) +\"-\"+ df[\"object\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map features in evaluation_df to predefined dictionaries\n",
    "evaluation_df['gender'] = evaluation_df['gender'].map(dict_data.gender_map)\n",
    "evaluation_df['Self-reported fluency level '] = evaluation_df['Self-reported fluency level '].map(dict_data.language_fluency_map)\n",
    "evaluation_df['ageRange'] = evaluation_df['ageRange'].map(dict_data.age_range_map)\n",
    "evaluation_df['Current language used for work/school'] = evaluation_df['Current language used for work/school'].map(dict_data.current_language_map)\n",
    "evaluation_df['First Language spoken'] = evaluation_df['First Language spoken'].map(dict_data.first_language_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.join(df['path'].apply(get_features))\n",
    "evaluation_df = evaluation_df.join(evaluation_df['path'].apply(get_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataframes from previously saved csv files so we don't need to get features again\n",
    "\n",
    "df = pd.read_csv(r'save_csv/training2.csv').iloc[:,1:]\n",
    "evaluation_df = pd.read_csv(r'save_csv/evaluation2.csv').iloc[:,1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_evaluation = evaluation_df.drop(['Id','path','speakerId'],axis=1)\n",
    "# x_evaluation = evaluation_df.drop(['Id','path','speakerId','Self-reported fluency level ','First Language spoken','gender','ageRange'],axis=1)\n",
    "\n",
    "x_evaluation.columns = x_evaluation.columns.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('save_csv/training2.csv')\n",
    "evaluation_df.to_csv('save_csv/evaluation2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# x = df.drop(['Id','path','speakerId','action','object','action-object','Self-reported fluency level ','First Language spoken','gender','ageRange'],axis=1)\n",
    "x = df.drop(['Id','path','speakerId','action','object','action-object'],axis=1)\n",
    "y = df[['action-object']].copy()\n",
    "\n",
    "# Change column names from Int to Str to avoid error by SKLEARN\n",
    "x.columns = x.columns.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply scaling for PCA since pca is sensitive to the scale of features.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(x)  # Don't cheat - fit only on training data\n",
    "X_scaled = scaler.transform(x)\n",
    "X_evaluation_scaled = scaler.transform(x_evaluation)  # apply same transformation to test data\n",
    "\n",
    "# X_scaled = scaler.fit_transform(x)\n",
    "# X_evaluation_scaled = scaler.fit_transform(x_evaluation)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=150).fit(X_scaled)\n",
    "X_pca = pca.transform(X_scaled)\n",
    "X_evaluation_pca = pca.transform(X_evaluation_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(pca.explained_variance_ratio_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_split splits the data into 80% training data and 20% test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_scaled, y,test_size = .2,random_state = 42, shuffle = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy Random Forest: 0.47234906139015725\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Create a Classifier\n",
    "rf_clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "\n",
    "#Train the model using the training sets \n",
    "rf_clf.fit(x_train,np.ravel(y_train))\n",
    "y_pred_rf=rf_clf.predict(x_test)\n",
    "\n",
    "# Model Accuracy using test data (20%)\n",
    "print(\"Test set accuracy Random Forest:\",metrics.accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy using SVM: 0.6463723997970573\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svm_clf = svm.SVC(kernel = 'rbf', C=10, gamma=0.01)\n",
    "svm_clf.fit(x_train,np.ravel(y_train))\n",
    "y_pred_svm=svm_clf.predict(x_test)\n",
    "\n",
    "\n",
    "print(\"Test set accuracy using SVM:\",metrics.accuracy_score(y_test, y_pred_svm))\n",
    "\n",
    "# 0.646\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'C': 10, 'gamma': 0.01}\n",
      "Best score:  0.5388801153904927\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for the SVM\n",
    "param_grid = {'C': [0.1, 1, 10], 'gamma': [0.01, 0.1, 1]}\n",
    "\n",
    "# Create a SVM with an RBF kernel\n",
    "svm = SVC(kernel='rbf')\n",
    "\n",
    "# Perform the grid search using 10-fold cross-validation\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=2)\n",
    "grid_search.fit(x_train, np.ravel(y_train))\n",
    "\n",
    "# Print the best parameters and the corresponding mean test score\n",
    "print(\"Best parameters: \",grid_search.best_params_)\n",
    "print(\"Best score: \",grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_evaluation=svm_clf.predict(X_evaluation_scaled)\n",
    "\n",
    "y_evaluation = list(map(lambda s: s.replace(\"-\", \"\"), y_evaluation))\n",
    "\n",
    "y_evaluation_df = pd.DataFrame(y_evaluation, columns = ['Predicted'])\n",
    "y_evaluation_df.index.name = 'Id'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = int(time.time())\n",
    "\n",
    "y_evaluation_df.to_csv(f'evaluation/copy_predictions{now}.csv',index=True,header=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d632ece9ffddb0af8003b7fd18727f76c563889d1c26c69682c14ed7f3fb0566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
