{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io.wavfile import read \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from algorithms import get_features\n",
    "import encode_dict_data \n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the address in 'url' variable\n",
    "data_path = \"dsl_data/development.csv\"\n",
    "evaluation_path = \"dsl_data/evaluation.csv\"\n",
    "\n",
    "# Importing the file from the address contained in 'url' into 'df' \n",
    "df = pd.read_csv(data_path)\n",
    "evaluation_df = pd.read_csv(evaluation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['native'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Discover that evaluation data only contains English (United States) and Native speakers\n",
    "evaluation_df['Current language used for work/school'].unique()\n",
    "evaluation_df['First Language spoken'].unique()\n",
    "evaluation_df['Self-reported fluency level '].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE all rows where language is not English and fluency is not native\n",
    "modified_df = df[df['First Language spoken'] == 'English (United States)']\n",
    "modified_df = modified_df[modified_df['Current language used for work/school'] == 'English (United States)']\n",
    "modified_df = modified_df[modified_df['Self-reported fluency level '] == 'native']\n",
    "\n",
    "df = modified_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in TRAINING dataset: 0\n",
      "Null values in EVALUATION dataset: 0\n"
     ]
    }
   ],
   "source": [
    "# Check null values in both datasets (pandas dataframe)\n",
    "print(\"Null values in TRAINING dataset:\",df.isnull().sum().sum())\n",
    "print(\"Null values in EVALUATION dataset:\",evaluation_df.isnull().sum().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'] = df['gender'].map(encode_dict_data.gender_map)\n",
    "df['Self-reported fluency level '] = df['Self-reported fluency level '].map(encode_dict_data.language_fluency_map)\n",
    "df['ageRange'] = df['ageRange'].map(encode_dict_data.age_range_map)\n",
    "df['Current language used for work/school'] = df['Current language used for work/school'].map(encode_dict_data.current_language_map)\n",
    "df['First Language spoken'] = df['First Language spoken'].map(encode_dict_data.first_language_map)\n",
    "\n",
    "\n",
    "# Try to combine action & object in 1 column\n",
    "df[\"action-object\"] = df['action'].astype(str) +\"-\"+ df[\"object\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map features in evaluation_df to predefined dictionaries\n",
    "evaluation_df['gender'] = evaluation_df['gender'].map(encode_dict_data.gender_map)\n",
    "evaluation_df['Self-reported fluency level '] = evaluation_df['Self-reported fluency level '].map(encode_dict_data.language_fluency_map)\n",
    "evaluation_df['ageRange'] = evaluation_df['ageRange'].map(encode_dict_data.age_range_map)\n",
    "evaluation_df['Current language used for work/school'] = evaluation_df['Current language used for work/school'].map(encode_dict_data.current_language_map)\n",
    "evaluation_df['First Language spoken'] = evaluation_df['First Language spoken'].map(encode_dict_data.first_language_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\algorithms\\get_features.py:8: FutureWarning: Pass y=[0.         0.         0.         ... 0.00045176 0.00017743 0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mfcc = librosa.feature.mfcc(data, sr = sample_rate, n_mfcc=30)\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\algorithms\\get_features.py:10: FutureWarning: Pass y=[0.         0.         0.         ... 0.00045176 0.00017743 0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  rolloff = librosa.feature.spectral_rolloff(data)[0]\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\algorithms\\get_features.py:11: FutureWarning: Pass y=[0.         0.         0.         ... 0.00045176 0.00017743 0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  spectral_centroid = librosa.feature.spectral_centroid(data)[0]\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\algorithms\\get_features.py:12: FutureWarning: Pass y=[0.         0.         0.         ... 0.00045176 0.00017743 0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  spectral_contrast = librosa.feature.spectral_contrast(data)[0]\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\algorithms\\get_features.py:13: FutureWarning: Pass y=[0.         0.         0.         ... 0.00045176 0.00017743 0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  spectral_bandwidth = librosa.feature.spectral_bandwidth(data)[0]\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\algorithms\\get_features.py:8: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  4.0316991e-05\n",
      " -7.0664035e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mfcc = librosa.feature.mfcc(data, sr = sample_rate, n_mfcc=30)\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\algorithms\\get_features.py:10: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  4.0316991e-05\n",
      " -7.0664035e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  rolloff = librosa.feature.spectral_rolloff(data)[0]\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\algorithms\\get_features.py:11: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  4.0316991e-05\n",
      " -7.0664035e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  spectral_centroid = librosa.feature.spectral_centroid(data)[0]\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\algorithms\\get_features.py:12: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  4.0316991e-05\n",
      " -7.0664035e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  spectral_contrast = librosa.feature.spectral_contrast(data)[0]\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\algorithms\\get_features.py:13: FutureWarning: Pass y=[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  4.0316991e-05\n",
      " -7.0664035e-05  0.0000000e+00] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  spectral_bandwidth = librosa.feature.spectral_bandwidth(data)[0]\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\algorithms\\get_features.py:8: FutureWarning: Pass y=[0.         0.         0.         ... 0.00024043 0.00012006 0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mfcc = librosa.feature.mfcc(data, sr = sample_rate, n_mfcc=30)\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\algorithms\\get_features.py:10: FutureWarning: Pass y=[0.         0.         0.         ... 0.00024043 0.00012006 0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  rolloff = librosa.feature.spectral_rolloff(data)[0]\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\algorithms\\get_features.py:11: FutureWarning: Pass y=[0.         0.         0.         ... 0.00024043 0.00012006 0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  spectral_centroid = librosa.feature.spectral_centroid(data)[0]\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\algorithms\\get_features.py:12: FutureWarning: Pass y=[0.         0.         0.         ... 0.00024043 0.00012006 0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  spectral_contrast = librosa.feature.spectral_contrast(data)[0]\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\algorithms\\get_features.py:13: FutureWarning: Pass y=[0.         0.         0.         ... 0.00024043 0.00012006 0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  spectral_bandwidth = librosa.feature.spectral_bandwidth(data)[0]\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\algorithms\\get_features.py:8: FutureWarning: Pass y=[0. 0. 0. ... 0. 0. 0.] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mfcc = librosa.feature.mfcc(data, sr = sample_rate, n_mfcc=30)\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\algorithms\\get_features.py:10: FutureWarning: Pass y=[0. 0. 0. ... 0. 0. 0.] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  rolloff = librosa.feature.spectral_rolloff(data)[0]\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\algorithms\\get_features.py:11: FutureWarning: Pass y=[0. 0. 0. ... 0. 0. 0.] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  spectral_centroid = librosa.feature.spectral_centroid(data)[0]\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\algorithms\\get_features.py:12: FutureWarning: Pass y=[0. 0. 0. ... 0. 0. 0.] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  spectral_contrast = librosa.feature.spectral_contrast(data)[0]\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\algorithms\\get_features.py:13: FutureWarning: Pass y=[0. 0. 0. ... 0. 0. 0.] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  spectral_bandwidth = librosa.feature.spectral_bandwidth(data)[0]\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\algorithms\\get_features.py:8: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00037219 -0.00050412\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mfcc = librosa.feature.mfcc(data, sr = sample_rate, n_mfcc=30)\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\algorithms\\get_features.py:10: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00037219 -0.00050412\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  rolloff = librosa.feature.spectral_rolloff(data)[0]\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\algorithms\\get_features.py:11: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00037219 -0.00050412\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  spectral_centroid = librosa.feature.spectral_centroid(data)[0]\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\algorithms\\get_features.py:12: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00037219 -0.00050412\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  spectral_contrast = librosa.feature.spectral_contrast(data)[0]\n",
      "c:\\Users\\asus rog\\Desktop\\audio-intent-detection\\algorithms\\get_features.py:13: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.00037219 -0.00050412\n",
      "  0.        ] as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  spectral_bandwidth = librosa.feature.spectral_bandwidth(data)[0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = df.join(df['path'].apply(get_features))\n",
    "evaluation_df = evaluation_df.join(evaluation_df['path'].apply(get_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataframes from previously saved csv files so we don't need to get features again\n",
    "\n",
    "# df = pd.read_csv(r'save_csv/training2.csv').iloc[:,1:]\n",
    "# evaluation_df = pd.read_csv(r'save_csv/evaluation2.csv').iloc[:,1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['Id','path','speakerId','action','object','action-object','Self-reported fluency level ','First Language spoken','Current language used for work/school'],axis=1)\n",
    "y = df[['action-object']].copy()\n",
    "x_evaluation = evaluation_df.drop(['Id','path','speakerId','Self-reported fluency level ','First Language spoken','Current language used for work/school'],axis=1)\n",
    "\n",
    "# Change column names from Int to Str to avoid error by SKLEARN\n",
    "x.columns = x.columns.astype(str)\n",
    "x_evaluation.columns = x_evaluation.columns.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('save_csv/training2.csv')\n",
    "evaluation_df.to_csv('save_csv/evaluation2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# x = df.drop(['Id','path','speakerId','action','object','action-object','Self-reported fluency level ','First Language spoken','gender','ageRange'],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>ageRange</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9010</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-472.125153</td>\n",
       "      <td>27.469360</td>\n",
       "      <td>-4.033377</td>\n",
       "      <td>58.852196</td>\n",
       "      <td>-15.320990</td>\n",
       "      <td>-11.096684</td>\n",
       "      <td>-24.349939</td>\n",
       "      <td>2.503482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625339</td>\n",
       "      <td>29.681489</td>\n",
       "      <td>14.797038</td>\n",
       "      <td>6.795048</td>\n",
       "      <td>2019.713124</td>\n",
       "      <td>296.428304</td>\n",
       "      <td>-0.245218</td>\n",
       "      <td>2452.725765</td>\n",
       "      <td>2030.348001</td>\n",
       "      <td>2452.725765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9011</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-455.439331</td>\n",
       "      <td>24.492832</td>\n",
       "      <td>-13.733780</td>\n",
       "      <td>60.796482</td>\n",
       "      <td>-12.364906</td>\n",
       "      <td>-15.249555</td>\n",
       "      <td>-29.531570</td>\n",
       "      <td>-1.985768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381687</td>\n",
       "      <td>26.648305</td>\n",
       "      <td>15.300624</td>\n",
       "      <td>5.630460</td>\n",
       "      <td>1966.114860</td>\n",
       "      <td>301.816662</td>\n",
       "      <td>-0.307614</td>\n",
       "      <td>2390.327270</td>\n",
       "      <td>1940.078524</td>\n",
       "      <td>2390.327270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9012</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-479.745331</td>\n",
       "      <td>20.624519</td>\n",
       "      <td>-15.172877</td>\n",
       "      <td>56.297703</td>\n",
       "      <td>-15.982334</td>\n",
       "      <td>-11.285934</td>\n",
       "      <td>-32.526470</td>\n",
       "      <td>2.319024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262787</td>\n",
       "      <td>27.473404</td>\n",
       "      <td>14.946695</td>\n",
       "      <td>6.785409</td>\n",
       "      <td>1980.747756</td>\n",
       "      <td>282.318874</td>\n",
       "      <td>-0.288538</td>\n",
       "      <td>2705.974911</td>\n",
       "      <td>2004.337230</td>\n",
       "      <td>2705.974911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  ageRange           0          1          2          3  \\\n",
       "9010       1         1 -472.125153  27.469360  -4.033377  58.852196   \n",
       "9011       1         1 -455.439331  24.492832 -13.733780  60.796482   \n",
       "9012       1         1 -479.745331  20.624519 -15.172877  56.297703   \n",
       "\n",
       "              4          5          6         7  ...       200        201  \\\n",
       "9010 -15.320990 -11.096684 -24.349939  2.503482  ...  0.625339  29.681489   \n",
       "9011 -12.364906 -15.249555 -29.531570 -1.985768  ...  0.381687  26.648305   \n",
       "9012 -15.982334 -11.285934 -32.526470  2.319024  ...  0.262787  27.473404   \n",
       "\n",
       "            202       203          204         205       206          207  \\\n",
       "9010  14.797038  6.795048  2019.713124  296.428304 -0.245218  2452.725765   \n",
       "9011  15.300624  5.630460  1966.114860  301.816662 -0.307614  2390.327270   \n",
       "9012  14.946695  6.785409  1980.747756  282.318874 -0.288538  2705.974911   \n",
       "\n",
       "              208          209  \n",
       "9010  2030.348001  2452.725765  \n",
       "9011  1940.078524  2390.327270  \n",
       "9012  2004.337230  2705.974911  \n",
       "\n",
       "[3 rows x 212 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply scaling for PCA since pca is sensitive to the scale of features.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(x)  # Don't cheat - fit only on training data\n",
    "X_scaled = scaler.transform(x)\n",
    "# X_evaluation_scaled = scaler.transform(x_evaluation)  # apply same transformation to test data\n",
    "\n",
    "# X_scaled = scaler.fit_transform(x)\n",
    "# X_evaluation_scaled = scaler.fit_transform(x_evaluation)\n",
    "\n",
    "\n",
    "# pca = PCA(n_components=150).fit(X_scaled)\n",
    "# X_pca = pca.transform(X_scaled)\n",
    "# X_evaluation_pca = pca.transform(X_evaluation_scaled)\n",
    "# print(sum(pca.explained_variance_ratio_)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_split splits the data into 80% training data and 20% test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_scaled, y,test_size = .2,random_state = 42, shuffle = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy Random Forest: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Create a Classifier\n",
    "rf_clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "\n",
    "#Train the model using the training sets \n",
    "rf_clf.fit(x_train,np.ravel(y_train))\n",
    "y_pred_rf=rf_clf.predict(x_test)\n",
    "\n",
    "# Model Accuracy using test data (20%)\n",
    "print(\"Test set accuracy Random Forest:\",metrics.accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action-object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9010</th>\n",
       "      <td>decrease-heat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9011</th>\n",
       "      <td>decrease-heat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9012</th>\n",
       "      <td>decrease-heat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      action-object\n",
       "9010  decrease-heat\n",
       "9011  decrease-heat\n",
       "9012  decrease-heat"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of classes has to be greater than one; got 1 class",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m svm_clf \u001b[39m=\u001b[39m svm\u001b[39m.\u001b[39mSVC(kernel \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrbf\u001b[39m\u001b[39m'\u001b[39m, C\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, gamma\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m svm_clf\u001b[39m.\u001b[39;49mfit(x_train,np\u001b[39m.\u001b[39;49mravel(y_train))\n\u001b[0;32m      3\u001b[0m y_pred_svm\u001b[39m=\u001b[39msvm_clf\u001b[39m.\u001b[39mpredict(x_test)\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTest set accuracy using SVM:\u001b[39m\u001b[39m\"\u001b[39m,metrics\u001b[39m.\u001b[39maccuracy_score(y_test, y_pred_svm))\n",
      "File \u001b[1;32mc:\\Users\\asus rog\\Desktop\\audio-intent-detection\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:201\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    192\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[0;32m    193\u001b[0m         X,\n\u001b[0;32m    194\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    199\u001b[0m     )\n\u001b[1;32m--> 201\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_targets(y)\n\u001b[0;32m    203\u001b[0m sample_weight \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\n\u001b[0;32m    204\u001b[0m     [] \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m sample_weight, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64\n\u001b[0;32m    205\u001b[0m )\n\u001b[0;32m    206\u001b[0m solver_type \u001b[39m=\u001b[39m LIBSVM_IMPL\u001b[39m.\u001b[39mindex(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl)\n",
      "File \u001b[1;32mc:\\Users\\asus rog\\Desktop\\audio-intent-detection\\venv\\lib\\site-packages\\sklearn\\svm\\_base.py:749\u001b[0m, in \u001b[0;36mBaseSVC._validate_targets\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_weight_ \u001b[39m=\u001b[39m compute_class_weight(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_weight, classes\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m, y\u001b[39m=\u001b[39my_)\n\u001b[0;32m    748\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mcls\u001b[39m) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m--> 749\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    750\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe number of classes has to be greater than one; got \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m class\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    751\u001b[0m         \u001b[39m%\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mcls\u001b[39m)\n\u001b[0;32m    752\u001b[0m     )\n\u001b[0;32m    754\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\n\u001b[0;32m    756\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray(y, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: The number of classes has to be greater than one; got 1 class"
     ]
    }
   ],
   "source": [
    "\n",
    "svm_clf = svm.SVC(kernel = 'rbf', C=10, gamma=0.01)\n",
    "svm_clf.fit(x_train,np.ravel(y_train))\n",
    "y_pred_svm=svm_clf.predict(x_test)\n",
    "\n",
    "\n",
    "print(\"Test set accuracy using SVM:\",metrics.accuracy_score(y_test, y_pred_svm))\n",
    "\n",
    "# 0.646\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for the SVM\n",
    "param_grid = {'C': [0.1, 1, 10], 'gamma': [0.01, 0.1, 1]}\n",
    "\n",
    "# Create a SVM with an RBF kernel\n",
    "svm = SVC(kernel='rbf')\n",
    "\n",
    "# Perform the grid search using 10-fold cross-validation\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=2)\n",
    "grid_search.fit(x_train, np.ravel(y_train))\n",
    "\n",
    "# Print the best parameters and the corresponding mean test score\n",
    "print(\"Best parameters: \",grid_search.best_params_)\n",
    "print(\"Best score: \",grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_evaluation=svm_clf.predict(X_evaluation_scaled)\n",
    "\n",
    "y_evaluation = list(map(lambda s: s.replace(\"-\", \"\"), y_evaluation))\n",
    "\n",
    "y_evaluation_df = pd.DataFrame(y_evaluation, columns = ['Predicted'])\n",
    "y_evaluation_df.index.name = 'Id'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = int(time.time())\n",
    "\n",
    "y_evaluation_df.to_csv(f'evaluation/copy_predictions{now}.csv',index=True,header=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d632ece9ffddb0af8003b7fd18727f76c563889d1c26c69682c14ed7f3fb0566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
